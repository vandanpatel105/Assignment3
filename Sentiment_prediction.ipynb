{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DnmqbJ8Z8x8W",
    "outputId": "3f1c6deb-b47d-4176-feab-a1d728ef9f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "vzePUbSU8yna",
    "outputId": "1bb2bd0e-d011-414f-e970-9abcb4f13045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import nltk\n",
    "import numpy\n",
    "nltk.download('punkt')\n",
    "from nltk import punkt\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize \n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv1D\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFni7Unk9LjS"
   },
   "outputs": [],
   "source": [
    "#importing files as text\n",
    "\n",
    "train_path = \"train.txt\"\n",
    "test_path = \"test.txt\"\n",
    "\n",
    "#in your case insert your path for train_path and test_path\n",
    "\n",
    "\n",
    "f = open(train_path, 'r')\n",
    "train_text = [j.split('\\n') for j in f.read().split('\\n\\n')]\n",
    "for i in range (len(train_text)):\n",
    "  for j in range (len(train_text[i])):\n",
    "    train_text[i][j] = train_text[i][j].split('\\t')\n",
    "    train_text[i][j][0] = train_text[i][j][0].lower()\n",
    "f.close()\n",
    "\n",
    "f = open(test_path, 'r')\n",
    "test_text = [j.split('\\n') for j in f.read().split('\\n\\n')]\n",
    "for i in range (len(test_text)):\n",
    "  for j in range (len(test_text[i])):\n",
    "    test_text[i][j].strip()\n",
    "    test_text[i][j] = test_text[i][j].split('\\t')\n",
    "    test_text[i][j][0] = test_text[i][j][0].lower()\n",
    "    # test_text[i][j][1].lower()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KY047pF39Zc0"
   },
   "outputs": [],
   "source": [
    "#converting the data in more meaningful way\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "\n",
    "for i in range (len(train_text)):\n",
    "    if len(train_text[i][0]) == 3:\n",
    "      temp_train = []\n",
    "      if train_text[i][0][2].lower() == \"positive\":\n",
    "        trainY.append(1)\n",
    "      elif train_text[i][0][2].lower() == \"neutral\":\n",
    "        trainY.append(0)\n",
    "      else:\n",
    "        trainY.append(-1)\n",
    "      for j in range (1,len(train_text[i])):\n",
    "        if len(train_text[i][j]) == 2:\n",
    "        # if train_text[i][j][1] != 'O' and len(train_text[i][j]) == 2:\n",
    "          temp_train.append(train_text[i][j])\n",
    "      trainX.append(temp_train)\n",
    "    # else:\n",
    "    #   print('wrong')\n",
    "\n",
    "for i in range (len(test_text)):\n",
    "  if len(test_text[i][0]) == 3:\n",
    "    temp_test = []\n",
    "    if test_text[i][0][2].lower() == \"positive\":\n",
    "      testY.append(1)\n",
    "    elif test_text[i][0][2].lower() == \"neutral\":\n",
    "      testY.append(0)\n",
    "    else:\n",
    "      testY.append(-1)\n",
    "    for j in range (1,len(test_text[i])):\n",
    "      if len(test_text[i][j]) == 2:\n",
    "      # if test_text[i][j][1] != 'O' and len(test_text[i][j]) == 2:\n",
    "        temp_test.append(test_text[i][j])\n",
    "    testX.append(temp_test)\n",
    "  # else:\n",
    "  #   print('wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8L4GNAGZCQm"
   },
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "max_length = max([len(i) for i in trainX])\n",
    "count = 0\n",
    "for i in range (len(trainX)):\n",
    "  for j in range (len(trainX[i])):\n",
    "    if trainX[i][j][0] not in dic:\n",
    "      count += 1\n",
    "      dic[trainX[i][j][0]] = count\n",
    "      trainX[i][j] = count\n",
    "    else:\n",
    "      trainX[i][j] = dic[trainX[i][j][0]]\n",
    "\n",
    "for i in range (len(testX)):\n",
    "  for j in range (len(testX[i])):\n",
    "    if testX[i][j][0] not in dic:\n",
    "      count += 1\n",
    "      dic[testX[i][j][0]] = count\n",
    "      testX[i][j] = count\n",
    "    else:\n",
    "      testX[i][j] = dic[testX[i][j][0]]\n",
    "\n",
    "# print(len(dic))\n",
    "# print(max_length)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rTGpHEsHFnf"
   },
   "outputs": [],
   "source": [
    "for i in range (len(trainX)):\n",
    "  trainX[i] = trainX[i] + [0]*(max_length-len(trainX[i]))\n",
    "\n",
    "for i in range (len(testX)):\n",
    "  testX[i] = testX[i] + [0]*(max_length-len(testX[i]))\n",
    "\n",
    "trainX = numpy.array(trainX)\n",
    "testX = numpy.array(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSDVO8YHMZdX"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "                    \n",
    "                    \n",
    "                    Dense(5000, input_shape=(max_length,), activation='linear'),\n",
    "                    Dense(1000, activation='sigmoid'),\n",
    "                    Dense(200, activation='tanh'),\n",
    "                    Dense(50, activation='tanh'),\n",
    "                    Dense(1, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "J6Z3MLZWPUjk",
    "outputId": "9951b391-2c35-4996-94c4-a02c777d8987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 5000)              285000    \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1000)              5001000   \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,496,301\n",
      "Trainable params: 5,496,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_bbJZUlQTRF"
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "uPoo99RbyOKl",
    "outputId": "98f5c8a4-fcbf-49a6-f788-8c49570617c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15131/15131 [==============================] - 11s 716us/step - loss: 0.6417 - acc: 0.3724\n",
      "Epoch 2/5\n",
      "15131/15131 [==============================] - 9s 572us/step - loss: 0.6178 - acc: 0.3733\n",
      "Epoch 3/5\n",
      "15131/15131 [==============================] - 9s 571us/step - loss: 0.6146 - acc: 0.3727\n",
      "Epoch 4/5\n",
      "15131/15131 [==============================] - 9s 583us/step - loss: 0.6141 - acc: 0.3723\n",
      "Epoch 5/5\n",
      "15131/15131 [==============================] - 9s 568us/step - loss: 0.6142 - acc: 0.3729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff487aae0b8>"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=10, epochs=5, validation_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "9NG4Z9luibk9",
    "outputId": "777a1b84-3693-4de7-c7f9-6697cc110021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869/1869 [==============================] - 1s 375us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5877378519490928, 0.4034242911046045]"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=testX, y=testY, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
