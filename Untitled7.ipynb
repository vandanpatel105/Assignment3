{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnmqbJ8Z8x8W",
        "colab_type": "code",
        "outputId": "76b94106-6ae3-462a-f44d-0ff5d35dccce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzePUbSU8yna",
        "colab_type": "code",
        "outputId": "4c8516fd-eae9-4f87-87a9-9afd83efa070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "import keras\n",
        "import nltk\n",
        "import numpy\n",
        "nltk.download('punkt')\n",
        "from nltk import punkt\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize \n",
        "from keras import backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Conv1D\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFni7Unk9LjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing files as text\n",
        "\n",
        "train_path = \"/content/drive/My Drive/nlp_assignment/train.txt\"\n",
        "test_path = \"/content/drive/My Drive/nlp_assignment/test.txt\"\n",
        "\n",
        "#in your case insert your path for train_path and test_path\n",
        "\n",
        "\n",
        "f = open(train_path, 'r')\n",
        "train_text = [j.split('\\n') for j in f.read().split('\\n\\n')]\n",
        "for i in range (len(train_text)):\n",
        "  for j in range (len(train_text[i])):\n",
        "    train_text[i][j] = train_text[i][j].split('\\t')\n",
        "    train_text[i][j][0] = train_text[i][j][0].lower()\n",
        "f.close()\n",
        "\n",
        "f = open(test_path, 'r')\n",
        "test_text = [j.split('\\n') for j in f.read().split('\\n\\n')]\n",
        "for i in range (len(test_text)):\n",
        "  for j in range (len(test_text[i])):\n",
        "    test_text[i][j].strip()\n",
        "    test_text[i][j] = test_text[i][j].split('\\t')\n",
        "    test_text[i][j][0] = test_text[i][j][0].lower()\n",
        "    # test_text[i][j][1].lower()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY047pF39Zc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting the data in more meaningful way\n",
        "\n",
        "trainX = []\n",
        "trainY = []\n",
        "testX = []\n",
        "testY = []\n",
        "\n",
        "for i in range (len(train_text)):\n",
        "    if len(train_text[i][0]) == 3:\n",
        "      temp_train = []\n",
        "      if train_text[i][0][2].lower() == \"positive\":\n",
        "        trainY.append(1)\n",
        "      elif train_text[i][0][2].lower() == \"neutral\":\n",
        "        trainY.append(0)\n",
        "      else:\n",
        "        trainY.append(-1)\n",
        "      for j in range (1,len(train_text[i])):\n",
        "        if len(train_text[i][j]) == 2:\n",
        "        # if train_text[i][j][1] != 'O' and len(train_text[i][j]) == 2:\n",
        "          temp_train.append(train_text[i][j])\n",
        "      trainX.append(temp_train)\n",
        "    # else:\n",
        "    #   print('wrong')\n",
        "\n",
        "for i in range (len(test_text)):\n",
        "  if len(test_text[i][0]) == 3:\n",
        "    temp_test = []\n",
        "    if test_text[i][0][2].lower() == \"positive\":\n",
        "      testY.append(1)\n",
        "    elif test_text[i][0][2].lower() == \"neutral\":\n",
        "      testY.append(0)\n",
        "    else:\n",
        "      testY.append(-1)\n",
        "    for j in range (1,len(test_text[i])):\n",
        "      if len(test_text[i][j]) == 2:\n",
        "      # if test_text[i][j][1] != 'O' and len(test_text[i][j]) == 2:\n",
        "        temp_test.append(test_text[i][j])\n",
        "    testX.append(temp_test)\n",
        "  # else:\n",
        "  #   print('wrong')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8L4GNAGZCQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = dict()\n",
        "max_length = max([len(i) for i in trainX])\n",
        "count = 0\n",
        "for i in range (len(trainX)):\n",
        "  for j in range (len(trainX[i])):\n",
        "    if trainX[i][j][0] not in dic:\n",
        "      count += 1\n",
        "      dic[trainX[i][j][0]] = count\n",
        "      trainX[i][j] = count\n",
        "    else:\n",
        "      trainX[i][j] = dic[trainX[i][j][0]]\n",
        "\n",
        "for i in range (len(testX)):\n",
        "  for j in range (len(testX[i])):\n",
        "    if testX[i][j][0] not in dic:\n",
        "      count += 1\n",
        "      dic[testX[i][j][0]] = count\n",
        "      testX[i][j] = count\n",
        "    else:\n",
        "      testX[i][j] = dic[testX[i][j][0]]\n",
        "\n",
        "# print(len(dic))\n",
        "# print(max_length)\n",
        "# print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rTGpHEsHFnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (len(trainX)):\n",
        "  trainX[i] = trainX[i] + [0]*(max_length-len(trainX[i]))\n",
        "\n",
        "for i in range (len(testX)):\n",
        "  testX[i] = testX[i] + [0]*(max_length-len(testX[i]))\n",
        "\n",
        "trainX = numpy.array(trainX)\n",
        "testX = numpy.array(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSDVO8YHMZdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "                    Dense(100, input_shape=(max_length,), activation='linear'),\n",
        "                    Dense(104, activation='sigmoid'),\n",
        "                    Dense(1, activation='tanh')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Z3MLZWPUjk",
        "colab_type": "code",
        "outputId": "92cc9196-8036-4d7a-878c-42f0430b3f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 100)               5700      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 104)               10504     \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 105       \n",
            "=================================================================\n",
            "Total params: 16,309\n",
            "Trainable params: 16,309\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_bbJZUlQTRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(lr=0.0001), loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f09d50b9-61a5-4a20-b7ff-bc3660ede1a8",
        "id": "uPoo99RbyOKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "model.fit(trainX, trainY, batch_size=10, epochs=5, validation_split=0)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "15131/15131 [==============================] - 6s 395us/step - loss: 0.8683 - acc: 0.3525\n",
            "Epoch 2/5\n",
            "15131/15131 [==============================] - 6s 364us/step - loss: 0.7678 - acc: 0.3665\n",
            "Epoch 3/5\n",
            "15131/15131 [==============================] - 5s 354us/step - loss: 0.7218 - acc: 0.3740\n",
            "Epoch 4/5\n",
            "15131/15131 [==============================] - 5s 351us/step - loss: 0.6994 - acc: 0.3739\n",
            "Epoch 5/5\n",
            "15131/15131 [==============================] - 5s 359us/step - loss: 0.6837 - acc: 0.3749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd91f9a4f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NG4Z9luibk9",
        "colab_type": "code",
        "outputId": "32f31700-3a9a-4945-bbf3-0da89a32b352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(x=testX, y=testY, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 0s 129us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6629139368007245, 0.40663456397779874]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLMzir1jjJfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1score = []\n",
        "recalls = []\n",
        "precisions = []\n",
        "\n",
        "predict = (numpy.array(model.predict(testX))).round() \n",
        "targ = testY\n",
        "f1 = f1_score(targ, predict,average=None)\n",
        "recall = recall_score(targ, predict,average=None)\n",
        "precision = precision_score(targ, predict,average=None)\n",
        "accuracy = accuracy_score(targ, predict)\n",
        "f1score.append(f1)\n",
        "recalls.append(recall)\n",
        "precisions.append(precision)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49oa38XTjTgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d6b0f87d-35df-438d-8c62-6bdce2885d78"
      },
      "source": [
        "print(\"f1_Positive: %f \\nf1_Negetive: %f \\nf1_Neutral: %f \\nprecision_Positive: %f \\nprecision_Negetive: %f \\nprecision_Neutral: %f \\nrecall_Positive %f \\nrecall_Negetive %f \\nrecall_Neutral %f \\nAccuracy: %f percent\" %(f1[0], f1[1], f1[2], precision[0], precision[1], precision[2], recall[0], recall[1], recall[2], accuracy*100))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_Positive: 0.103853 \n",
            "f1_Negetive: 0.559022 \n",
            "f1_Neutral: 0.171651 \n",
            "precision_Positive: 0.484375 \n",
            "precision_Negetive: 0.409765 \n",
            "precision_Neutral: 0.352941 \n",
            "recall_Positive 0.058161 \n",
            "recall_Negetive 0.879310 \n",
            "recall_Neutral 0.113402 \n",
            "Accuracy: 40.663456 percent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaDNuT6pjfgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}